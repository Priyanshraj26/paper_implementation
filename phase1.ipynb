{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adee6f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from scipy import signal\n",
    "import noisereduce as nr\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pyannote.audio import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c091ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing: interview_audio.wav\n",
      "==================================================\n",
      "\n",
      "1. Loading audio...\n",
      "   ✓ Loaded: 394.0s, 48000Hz\n",
      "\n",
      "2. Converting to mono...\n",
      "   ✓ Converted stereo to mono\n",
      "\n",
      "3. Removing noise...\n",
      "   ✓ Removed background noise (strength: 0.6)\n",
      "\n",
      "4. Removing silence...\n",
      "   ✓ Removed 39.5s of silence (20.1%)\n",
      "\n",
      "5. Downsampling for transcription...\n",
      "   ✓ Downsampled: 48000Hz → 16000Hz\n",
      "\n",
      "6. Saving processed audio...\n",
      "\n",
      "==================================================\n",
      "✓ COMPLETE!\n",
      "✓ Saved to: interview_cleaned.wav\n",
      "✓ Sample rate: 16000Hz (optimized for transcription)\n",
      "✓ Original: 394.0s → Final: 157.5s\n",
      "✓ Total removed: 236.5s\n",
      "==================================================\n",
      "\n",
      "✓ Audio cleaning complete!\n",
      "✓ Audio is ready for transcription at 16000Hz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Try to import noisereduce\n",
    "try:\n",
    "    import noisereduce as nr\n",
    "    NOISEREDUCE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    NOISEREDUCE_AVAILABLE = False\n",
    "    print(\"Warning: noisereduce not installed. Install with: pip install noisereduce\")\n",
    "\n",
    "class SimpleAudioCleaner:\n",
    "    \"\"\"\n",
    "    Simple audio processor that ONLY:\n",
    "    1. Converts to mono\n",
    "    2. Removes noise\n",
    "    3. Removes silence\n",
    "    4. Downsamples for transcription\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, silence_threshold_db=-40, min_silence_duration_ms=500, \n",
    "                 noise_reduce_strength=0.6, target_sample_rate=16000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            silence_threshold_db: Volume level below which audio is considered silence (default -40dB)\n",
    "            min_silence_duration_ms: Minimum duration of silence to remove (default 500ms)\n",
    "            noise_reduce_strength: Strength of noise reduction 0.0-1.0 (default 0.6)\n",
    "            target_sample_rate: Target sample rate for transcription (default 16000Hz, set to None to keep original)\n",
    "        \"\"\"\n",
    "        self.silence_threshold_db = silence_threshold_db\n",
    "        self.min_silence_duration_ms = min_silence_duration_ms\n",
    "        self.noise_reduce_strength = noise_reduce_strength\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "\n",
    "    \n",
    "    def convert_to_mono(self, audio):\n",
    "        \"\"\"Convert stereo to mono by averaging channels\"\"\"\n",
    "        if audio.ndim == 2:\n",
    "            # Average the channels\n",
    "            mono = np.mean(audio, axis=0)\n",
    "            print(f\"   ✓ Converted stereo to mono\")\n",
    "            return mono\n",
    "        else:\n",
    "            print(f\"   ✓ Already mono\")\n",
    "            return audio\n",
    "    \n",
    "    def remove_noise(self, audio, sr):\n",
    "        \"\"\"Remove background noise with adjustable strength\"\"\"\n",
    "        if not NOISEREDUCE_AVAILABLE:\n",
    "            print(f\"   ⚠ Skipping noise reduction (noisereduce not installed)\")\n",
    "            return audio\n",
    "        \n",
    "        try:\n",
    "            # Gentle noise reduction with adjustable parameters\n",
    "            cleaned = nr.reduce_noise(\n",
    "                y=audio, \n",
    "                sr=sr,\n",
    "                prop_decrease=self.noise_reduce_strength,  # How much to reduce noise (0.0-1.0)\n",
    "                stationary=True,  # Assume noise is consistent throughout\n",
    "                freq_mask_smooth_hz=500,  # Smoothing in frequency domain (prevents artifacts)\n",
    "                time_mask_smooth_ms=50    # Smoothing in time domain (prevents artifacts)\n",
    "            )\n",
    "            print(f\"   ✓ Removed background noise (strength: {self.noise_reduce_strength})\")\n",
    "            return cleaned\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠ Noise reduction failed: {e}\")\n",
    "            return audio\n",
    "    \n",
    "    def remove_silence(self, audio, sr):\n",
    "        \"\"\"Remove silent parts from audio\"\"\"\n",
    "        \n",
    "        # Use librosa to detect non-silent intervals\n",
    "        intervals = librosa.effects.split(\n",
    "            audio,\n",
    "            top_db=-self.silence_threshold_db,\n",
    "            frame_length=2048,\n",
    "            hop_length=512\n",
    "        )\n",
    "        \n",
    "        # Concatenate non-silent parts\n",
    "        non_silent_parts = []\n",
    "        \n",
    "        for start, end in intervals:\n",
    "            non_silent_parts.append(audio[start:end])\n",
    "        \n",
    "        if non_silent_parts:\n",
    "            # Join all non-silent parts\n",
    "            cleaned = np.concatenate(non_silent_parts)\n",
    "            \n",
    "            # Calculate how much was removed\n",
    "            original_duration = len(audio) / sr\n",
    "            new_duration = len(cleaned) / sr\n",
    "            removed_duration = original_duration - new_duration\n",
    "            removed_percent = (removed_duration / original_duration) * 100\n",
    "            \n",
    "            print(f\"   ✓ Removed {removed_duration:.1f}s of silence ({removed_percent:.1f}%)\")\n",
    "            return cleaned\n",
    "        else:\n",
    "            print(f\"   ⚠ No audio remained after silence removal, keeping original\")\n",
    "            return audio\n",
    "    \n",
    "    def downsample_audio(self, audio, original_sr, target_sr):\n",
    "        \"\"\"Downsample audio to target sample rate for transcription\"\"\"\n",
    "        if target_sr is None or original_sr == target_sr:\n",
    "            print(f\"   ✓ Keeping original sample rate: {original_sr}Hz\")\n",
    "            return audio, original_sr\n",
    "        \n",
    "        try:\n",
    "            # Resample using librosa's high-quality resampler\n",
    "            resampled = librosa.resample(audio, orig_sr=original_sr, target_sr=target_sr)\n",
    "            print(f\"   ✓ Downsampled: {original_sr}Hz → {target_sr}Hz\")\n",
    "            return resampled, target_sr\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠ Downsampling failed: {e}, keeping original sample rate\")\n",
    "            return audio, original_sr\n",
    "    \n",
    "    def process(self, input_path, output_path):\n",
    "        \"\"\"\n",
    "        Process audio file: convert to mono, remove noise, remove silence, downsample\n",
    "        \n",
    "        Args:\n",
    "            input_path: Path to input audio file\n",
    "            output_path: Path to save processed audio\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing: {input_path}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Step 1: Load audio (keeping original sample rate)\n",
    "        print(f\"\\n1. Loading audio...\")\n",
    "        audio, sr = librosa.load(input_path, sr=None, mono=False)\n",
    "        original_duration = len(audio.flatten()) / sr if audio.ndim == 2 else len(audio) / sr\n",
    "        print(f\"   ✓ Loaded: {original_duration:.1f}s, {sr}Hz\")\n",
    "        \n",
    "        # Step 2: Convert to mono\n",
    "        print(f\"\\n2. Converting to mono...\")\n",
    "        audio = self.convert_to_mono(audio)\n",
    "        \n",
    "        # Step 3: Remove noise\n",
    "        print(f\"\\n3. Removing noise...\")\n",
    "        audio = self.remove_noise(audio, sr)\n",
    "        \n",
    "        # Step 4: Remove silence\n",
    "        print(f\"\\n4. Removing silence...\")\n",
    "        audio = self.remove_silence(audio, sr)\n",
    "        \n",
    "        # Step 5: Downsample for transcription\n",
    "        print(f\"\\n5. Downsampling for transcription...\")\n",
    "        audio, sr = self.downsample_audio(audio, sr, self.target_sample_rate)\n",
    "        \n",
    "        # Step 6: Save\n",
    "        print(f\"\\n6. Saving processed audio...\")\n",
    "        sf.write(output_path, audio, sr, subtype='PCM_16')\n",
    "        \n",
    "        # Final stats\n",
    "        final_duration = len(audio) / sr\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"✓ COMPLETE!\")\n",
    "        print(f\"✓ Saved to: {output_path}\")\n",
    "        print(f\"✓ Sample rate: {sr}Hz (optimized for transcription)\")\n",
    "        print(f\"✓ Original: {original_duration:.1f}s → Final: {final_duration:.1f}s\")\n",
    "        print(f\"✓ Total removed: {original_duration - final_duration:.1f}s\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "        \n",
    "        return audio, sr\n",
    "\n",
    "# Simple usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Create cleaner with custom settings if needed\n",
    "    cleaner = SimpleAudioCleaner(\n",
    "        silence_threshold_db=-40,  # Adjust this if it's removing too much/little\n",
    "        min_silence_duration_ms=700,  # Minimum silence duration to remove\n",
    "        noise_reduce_strength=0.6,  # 0.0-1.0: Lower = gentler noise reduction\n",
    "        target_sample_rate=16000  # 16kHz is optimal for most speech-to-text models\n",
    "                                   # Set to None to keep original sample rate\n",
    "    )\n",
    "    \n",
    "    # Process your file\n",
    "    input_file = \"interview_audio.wav\"\n",
    "    output_file = \"interview_cleaned.wav\"\n",
    "    \n",
    "    try:\n",
    "        audio, sr = cleaner.process(input_file, output_file)\n",
    "        print(\"✓ Audio cleaning complete!\")\n",
    "        print(f\"✓ Audio is ready for transcription at {sr}Hz\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {input_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
